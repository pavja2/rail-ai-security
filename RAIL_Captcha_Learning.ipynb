{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RAIL - Captcha Learning",
      "version": "0.3.2",
      "views": {},
      "default_view": {},
      "provenance": [],
      "collapsed_sections": [
        "WII2OKx2fBCk"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "Df0gtGHQeNJt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Exercise and Training Data Source: \n",
        "`https://medium.com/@ageitgey/how-to-break-a-captcha-system-in-15-minutes-with-machine-learning-dbebb035a710`\n",
        "\n",
        "Good Resource to Learn More About Convolutional Neural Networks: https://medium.com/@ageitgey/machine-learning-is-fun-part-3-deep-learning-and-convolutional-neural-networks-f40359318721"
      ]
    },
    {
      "metadata": {
        "id": "oPAWwd3BgSMz",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install keras\n",
        "!pip install imutils"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KgB68aVjs2S7",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# https://opencv.org/\n",
        "!apt-get -qq install -y libsm6 libxext6 && pip install -q -U opencv-python\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AWL6aKD-jJdV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Get our training data uploaded"
      ]
    },
    {
      "metadata": {
        "id": "_NkTB9unjFlL",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "  print(str(fn))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1gTr_6PZlkXL",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "with open(\"generated_captcha_images.zip\", \"wb\") as f:\n",
        "  print(list(uploaded.keys()))\n",
        "  f.write(uploaded[list(uploaded.keys())[0]])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "L_xoe-UimGHV",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "zip_ref = zipfile.ZipFile(list(uploaded.keys())[0])\n",
        "zip_ref.extractall('generated_captcha_images')\n",
        "zip_ref.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aUQj3LtGkkni",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!ls generated_captcha_images/generated_captcha_images"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "i8rrQ-YMrPgP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Turn the training data into actionable examples"
      ]
    },
    {
      "metadata": {
        "id": "x7cP4Nmmucb5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###Image Processing"
      ]
    },
    {
      "metadata": {
        "id": "XiIlBlgCwY6N",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "import os.path\n",
        "import cv2\n",
        "import glob\n",
        "import imutils\n",
        "\n",
        "CAPTCHA_IMAGE_FOLDER = \"generated_captcha_images/generated_captcha_images\"\n",
        "OUTPUT_FOLDER = \"extracted_letter_images\"\n",
        "\n",
        "# Get a list of all the captcha images we need to process\n",
        "captcha_image_files = glob.glob(os.path.join(CAPTCHA_IMAGE_FOLDER, \"*\"))\n",
        "counts = {}\n",
        "\n",
        "# loop over the image paths\n",
        "for (i, captcha_image_file) in enumerate(captcha_image_files):\n",
        "    print(\"[INFO] processing image {}/{}\".format(i + 1, len(captcha_image_files)))\n",
        "\n",
        "    # Since the filename contains the captcha text (i.e. \"2A2X.png\" has the text \"2A2X\"),\n",
        "    # grab the base filename as the text\n",
        "    filename = os.path.basename(captcha_image_file)\n",
        "    captcha_correct_text = os.path.splitext(filename)[0]\n",
        "\n",
        "    # Load the image and convert it to grayscale\n",
        "    image = cv2.imread(captcha_image_file)\n",
        "    gray = cv2.imread(captcha_image_file, 0)\n",
        "\n",
        "    # Add some extra padding around the image\n",
        "    gray = cv2.copyMakeBorder(gray, 8, 8, 8, 8, cv2.BORDER_REPLICATE)\n",
        "\n",
        "    # threshold the image (convert it to pure black and white)\n",
        "    thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV | cv2.THRESH_OTSU)[1]\n",
        "\n",
        "    # find the contours (continuous blobs of pixels) the image\n",
        "    contours = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "    # Hack for compatibility with different OpenCV versions\n",
        "    contours = contours[0] if imutils.is_cv2() else contours[1]\n",
        "\n",
        "    letter_image_regions = []\n",
        "\n",
        "    # Now we can loop through each of the four contours and extract the letter\n",
        "    # inside of each one\n",
        "    for contour in contours:\n",
        "        # Get the rectangle that contains the contour\n",
        "        (x, y, w, h) = cv2.boundingRect(contour)\n",
        "\n",
        "        # Compare the width and height of the contour to detect letters that\n",
        "        # are conjoined into one chunk\n",
        "        if w / h > 1.25:\n",
        "            # This contour is too wide to be a single letter!\n",
        "            # Split it in half into two letter regions!\n",
        "            half_width = int(w / 2)\n",
        "            letter_image_regions.append((x, y, half_width, h))\n",
        "            letter_image_regions.append((x + half_width, y, half_width, h))\n",
        "        else:\n",
        "            # This is a normal letter by itself\n",
        "            letter_image_regions.append((x, y, w, h))\n",
        "\n",
        "    # If we found more or less than 4 letters in the captcha, our letter extraction\n",
        "    # didn't work correcly. Skip the image instead of saving bad training data!\n",
        "    if len(letter_image_regions) != 4:\n",
        "        continue\n",
        "\n",
        "    # Sort the detected letter images based on the x coordinate to make sure\n",
        "    # we are processing them from left-to-right so we match the right image\n",
        "    # with the right letter\n",
        "    letter_image_regions = sorted(letter_image_regions, key=lambda x: x[0])\n",
        "\n",
        "    # Save out each letter as a single image\n",
        "    for letter_bounding_box, letter_text in zip(letter_image_regions, captcha_correct_text):\n",
        "        # Grab the coordinates of the letter in the image\n",
        "        x, y, w, h = letter_bounding_box\n",
        "\n",
        "        # Extract the letter from the original image with a 2-pixel margin around the edge\n",
        "        letter_image = gray[y - 2:y + h + 2, x - 2:x + w + 2]\n",
        "\n",
        "        # Get the folder to save the image in\n",
        "        save_path = os.path.join(OUTPUT_FOLDER, letter_text)\n",
        "\n",
        "        # if the output directory does not exist, create it\n",
        "        if not os.path.exists(save_path):\n",
        "            os.makedirs(save_path)\n",
        "\n",
        "        # write the letter image to a file\n",
        "        count = counts.get(letter_text, 1)\n",
        "        p = os.path.join(save_path, \"{}.png\".format(str(count).zfill(6)))\n",
        "        cv2.imwrite(p, letter_image)\n",
        "\n",
        "        # increment the count for the current key\n",
        "        counts[letter_text] = count + 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nU8qumjptZQM",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import imutils\n",
        "\n",
        "def resize_to_fit(image, width, height):\n",
        "    \"\"\"\n",
        "    A helper function to resize an image to fit within a given size\n",
        "    :param image: image to resize\n",
        "    :param width: desired width in pixels\n",
        "    :param height: desired height in pixels\n",
        "    :return: the resized image\n",
        "    \"\"\"\n",
        "\n",
        "    # grab the dimensions of the image, then initialize\n",
        "    # the padding values\n",
        "    (h, w) = image.shape[:2]\n",
        "\n",
        "    # if the width is greater than the height then resize along\n",
        "    # the width\n",
        "    if w > h:\n",
        "        image = imutils.resize(image, width=width)\n",
        "\n",
        "    # otherwise, the height is greater than the width so resize\n",
        "    # along the height\n",
        "    else:\n",
        "        image = imutils.resize(image, height=height)\n",
        "\n",
        "    # determine the padding values for the width and height to\n",
        "    # obtain the target dimensions\n",
        "    padW = int((width - image.shape[1]) / 2.0)\n",
        "    padH = int((height - image.shape[0]) / 2.0)\n",
        "\n",
        "    # pad the image then apply one more resizing to handle any\n",
        "    # rounding issues\n",
        "    image = cv2.copyMakeBorder(image, padH, padH, padW, padW,\n",
        "        cv2.BORDER_REPLICATE)\n",
        "    image = cv2.resize(image, (width, height))\n",
        "\n",
        "    # return the pre-processed image\n",
        "    return image"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dAv_4_67rVVJ",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from imutils import paths\n",
        "import cv2\n",
        "import numpy as np\n",
        "import os.path\n",
        "\n",
        "data = []\n",
        "labels = []\n",
        "for image_file in paths.list_images(OUTPUT_FOLDER):\n",
        "  image = cv2.imread(image_file)\n",
        "  image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "  \n",
        "  image = resize_to_fit(image, 20, 20)\n",
        "  \n",
        "  image = np.expand_dims(image, axis=2)\n",
        "  \n",
        "  label = image_file.split(os.path.sep)[-2]\n",
        "  data.append(image)\n",
        "  labels.append(label)\n",
        "print(\"Images: \", len(data))\n",
        "print(\"Labels: \", len(labels))\n",
        "\n",
        "#still more image processing\n",
        "\n",
        "data = np.array(data, dtype=\"float\") / 255.0\n",
        "labels = np.array(labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eilWDsazujNQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Data Setup"
      ]
    },
    {
      "metadata": {
        "id": "erjucEKjuiG2",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#Training and test data sets\n",
        "(X_train, X_test, Y_train, Y_test) = train_test_split(data, labels, test_size=0.25, random_state=0)\n",
        "\n",
        "# some label formatting for Keras\n",
        "lb = LabelBinarizer().fit(Y_train)\n",
        "Y_train = lb.transform(Y_train)\n",
        "Y_test = lb.transform(Y_test)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WII2OKx2fBCk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Build a neural network model (pretend it's magic)"
      ]
    },
    {
      "metadata": {
        "id": "Jsn30wkjeUFF",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
        "from keras.layers.core import Flatten, Dense\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(20, (5,5), padding=\"same\", input_shape=(20, 20, 1), activation=\"relu\"))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(50, (5, 5), padding=\"same\", activation=\"relu\"))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(500, activation=\"relu\"))\n",
        "\n",
        "model.add(Dense(32, activation=\"softmax\"))\n",
        "\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "75hr2Uc0u9wg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Train the neural network (magic continues)"
      ]
    },
    {
      "metadata": {
        "id": "DPjMl_qMvA_M",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "model.fit(X_train, Y_train, validation_data=(X_test, Y_test), batch_size=32, epochs=2, verbose=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZwTSn9VXzhF9",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# we can save our model so we don't have to build it every time\n",
        "\n",
        "from google.colab import files\n",
        "import pickle\n",
        "\n",
        "model.save('trained_model.hbf5')\n",
        "\n",
        "with open('trained_labels.pickle', 'wb') as f:\n",
        "  pickle.dump(lb, f)\n",
        " \n",
        "files.download('trained_model.hbf5')\n",
        "files.download('trained_labels.pickle')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}